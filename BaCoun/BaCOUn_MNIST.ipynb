{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaCOUn_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdFZNH19aQMJ"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import softmax\n",
        "from autograd import grad\n",
        "import theano\n",
        "import autograd.numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import pymc3 as pm\n",
        "import theano.tensor as T"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmTdmG1Y6dl5"
      },
      "source": [
        "def softmax1(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=1)[:,None]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgaYUmWXnOb3"
      },
      "source": [
        "X, y = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "\n",
        "# Pick out 3 classes of digits: 0, 1, 2 and take a subset of samples as in-distribution points\n",
        "X_0, y_0 = X[(y == '0')][:500], y[(y == '0')][:500].astype(int)\n",
        "X_1, y_1 = X[(y == '1')][:500], y[(y == '1')][:500].astype(int)\n",
        "X_2, y_2 = X[(y == '2')][:500], y[(y == '2')][:500].astype(int)\n",
        "\n",
        "X_ood, y_ood = X[(y == '3')][:500], ['OOD'] * 500"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZnOGOFwnqXF"
      },
      "source": [
        "# combine data\n",
        "X_mnist_ood = np.concatenate((X_0, X_1, X_2,X_ood))\n",
        "y_mnist_ood = np.concatenate((y_0, y_1, y_2,y_ood))\n",
        "\n",
        "X_mnist = np.concatenate((X_0, X_1, X_2))\n",
        "y_mnist = np.concatenate((y_0, y_1, y_2))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7WFBR1GnSl4",
        "outputId": "9ea625b1-7813-464a-ed53-1d588932262c"
      },
      "source": [
        "def MNIST_NN(X,Y, input_shape, nc, batch_size, epochs, loss):\n",
        "    # separate data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, \n",
        "                                                        stratify = Y, random_state=0)\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(pd.get_dummies(y_train))\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(pd.get_dummies(y_test))\n",
        "    print(\"Shape of data: \", x_train.shape,y_train.shape, x_test.shape,y_test.shape)\n",
        "    # train the model  \n",
        "    batch_size = batch_size\n",
        "    epochs = epochs\n",
        "    \n",
        "    model = make_model(input_shape=input_shape, num_classes=nc)\n",
        "    model.compile(loss = loss, optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,verbose=0)\n",
        "    # evaluation \n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print(\"Test loss:\", score[0])\n",
        "    print(\"Test accuracy:\", score[1])\n",
        "    pred = model.predict(x_test)\n",
        "    print(pred.shape)\n",
        "    auc = roc_auc_score(y_test, pred)\n",
        "    print(\"AUC: \", auc)\n",
        "    return model \n",
        "\n",
        "model = MNIST_NN(X_mnist_ood,y_mnist_ood, 784, 3+1, 32, 15,  \"categorical_crossentropy\")\n",
        "intermediate_layer_model = keras.Model(inputs=model.input,\n",
        "                                       outputs=model.get_layer(index = 4).output)\n",
        "\n",
        "intermediate_output = np.array(intermediate_layer_model(np.array(X_mnist)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data:  (1400, 784) (1400, 4) (600, 784) (600, 4)\n",
            "Test loss: 0.42664089798927307\n",
            "Test accuracy: 0.95333331823349\n",
            "(600, 4)\n",
            "AUC:  0.9923240740740741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQIcjiomnsxy",
        "outputId": "4be3def3-51ec-40a9-8928-6fbfe70cf12e"
      },
      "source": [
        "intermediate_output.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtACWMMsn3FL",
        "outputId": "f18e389f-14ac-4939-c0cd-3a75e47dd8de"
      },
      "source": [
        "theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n",
        "nc = 3 # 3 classes\n",
        "D = nc * (intermediate_output.shape[1] + 1) \n",
        "x = intermediate_output\n",
        "y = np.array(y_mnist)\n",
        "Priord = 1\n",
        "x_with_constant = np.hstack((x, np.ones((x.shape[0], 1), dtype=x.dtype)))\n",
        "with pm.Model() as bayesian_model:\n",
        "    #define priors\n",
        "    W = pm.Normal('W', mu=0, tau=1./(Priord**2), shape= D)\n",
        "    \n",
        "    p = pm.math.dot(x_with_constant, W.reshape((-1,nc))) \n",
        "    \n",
        "    #softmax\n",
        "    theta = T.nnet.softmax(p)\n",
        "    #define binomial likelihood\n",
        "    y_obs = pm.Categorical('y_obs',  p=theta, observed=y)\n",
        "    step = pm.Metropolis()\n",
        "    trace = pm.sample(5000,step,tune = 10000,chains = 2)\n",
        "thinned_trace = trace[::1]['W']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential sampling (2 chains in 1 job)\n",
            "Metropolis: [W]\n",
            "100%|██████████| 15000/15000 [28:40<00:00,  8.72it/s]\n",
            "100%|██████████| 15000/15000 [28:39<00:00,  8.72it/s]\n",
            "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
            "The estimated number of effective samples is smaller than 200 for some parameters.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHbIzvK2n8yP",
        "outputId": "e1f460ab-61aa-402b-d86f-765ac720dded"
      },
      "source": [
        "intermediate_layer_model = keras.Model(inputs=model.input, outputs=model.get_layer(index = 4).output)\n",
        "\n",
        "output_in = np.array(intermediate_layer_model(np.array(X_mnist)))\n",
        "output_ood = np.array(intermediate_layer_model(np.array(X_ood)))\n",
        "in_withc = np.hstack((output_in,np.ones((output_in.shape[0],1),dtype = output_in.dtype)))\n",
        "ood_withc = np.hstack((output_ood,np.ones((output_ood.shape[0],1),dtype = output_ood.dtype)))\n",
        "\n",
        "#calculate uncertainty(using variance)\n",
        "rand_samples = thinned_trace #[:700] #changed depending on sample!!!!!\n",
        "all_preds_in = []\n",
        "all_preds_ood = []\n",
        "for W in rand_samples:\n",
        "    all_preds_in.append(softmax1(in_withc @ np.array(W).reshape((-1,nc))))\n",
        "    all_preds_ood.append(softmax1(ood_withc @ np.array(W).reshape((-1,nc))))\n",
        "#assign predicted labels\n",
        "mean_label_in = np.argmax(np.mean(all_preds_in,axis = 0),axis = 1)\n",
        "mean_label_ood = np.argmax(np.mean(all_preds_ood,axis = 0),axis = 1)\n",
        "\n",
        "#assign uncertainty (using variance)\n",
        "varss_in = np.var(all_preds_in,axis = 0)\n",
        "var_in= np.mean([varss_in[i][mean_label_in[i]] for i in range(len(varss_in))])\n",
        "\n",
        "varss_ood = np.var(all_preds_ood,axis = 0)\n",
        "var_ood= np.mean([varss_ood[i][mean_label_ood[i]] for i in range(len(varss_ood))])  \n",
        "\n",
        "print(\"Uncertainty for in distribution data is \",var_in)\n",
        "print(\"Uncertainty for ood data is \", var_ood)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uncertainty for in distribution data is  1.00503935694972e-06\n",
            "Uncertainty for ood data is  6.4134650907512935e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StcJozdspHKN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}